{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "jFH1bDO3-8kd",
    "outputId": "3c42cdaa-b98f-448d-fb22-85036645e81a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "873voJSBABod",
    "outputId": "33bdb1a1-5e15-4261-bf17-dea4bc288081"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/Colab Notebooks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "4pL4gKTcANtM",
    "outputId": "96e5a16f-b301-4d0f-9a5f-cdda3309e0a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/Colab Notebooks\n",
      " chatbot2.0.ipynb\t   'Copy of chatbotPresents4.0.ipynb'\n",
      " chatbot4.0.ipynb\t    Data\n",
      " chatbotPresents4.0.ipynb   decoder_serialized.pt\n",
      " chatbotSports3.0.ipynb     encoder_serialized.pt\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "path_to_mount = '/content/drive/My Drive/Colab Notebooks/'\n",
    "\n",
    "os.chdir(path_to_mount)\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "TrYlIIi9AWBn",
    "outputId": "af7be6ad-3e20-4f5b-f427-b0d6661441a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import re\n",
    "import random\n",
    "import glob\n",
    "import json\n",
    "\n",
    "\n",
    "# Use GPU if available\n",
    "if (torch.cuda.is_available()):\n",
    "    device = torch.device('cuda')\n",
    "    print(\"Running on GPU\")\n",
    "else: \n",
    "    device = torch.device('cpu')\n",
    "    print(\"Running on CPU\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "-Syyai4YAlS7",
    "outputId": "ffeef0ff-3ed1-4aae-80fc-f65547f28707"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/content/drive/My Drive/Colab Notebooks/Data/data/dialogues/PRESENT_IDEAS.txt']\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "dialogues_regex_folder_path = \"Data/data/dialogues/*.txt\"\n",
    "\n",
    "list_of_files = glob.glob(path_to_mount + dialogues_regex_folder_path)\n",
    "print(list_of_files)\n",
    "print(len(list_of_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V3RR8sgNG1YZ"
   },
   "outputs": [],
   "source": [
    "dicts= [] \n",
    "\n",
    "\n",
    "for filename in list_of_files:\n",
    "  with open(filename) as f:\n",
    "      for line in f: \n",
    "          dicts.append(json.loads(line)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "oLLaw-TOHbIz",
    "outputId": "4e493c8d-0960-4166-bd75-3777e7299480"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "663\n",
      "[{'turns': ['Hello how may I help you?', 'I need help buying a gift', 'What kind of gift would you like to buy?', \"It's for a 2 year old baby\", 'How do you know the 2 year old baby?', \"It's a friend's kid.\", 'A teddy bear is a great gift.', 'She already has a bunch.', 'Does she have any huge teddy bears?', 'No. That might work, thanks.', \"You're welcome.\"]}, {'turns': ['Hello how may I help you?', 'I would like to get my spouse a gift.', 'is it for a special occasion?', 'Yes, it is his 53th birthday. I need help with ideas.', 'what is he interested in?', 'He likes motorcycles, the outdoors, and camping.', 'maybe some tents or any camping gear', 'Unfortunately, he has those items already.', 'how about motorcyle gear like a helmet that hooks up to your cellphone?', 'Do you have any other ideas?', 'a trip which is expensive to a luxurious camp site in the amazons', 'That seems like a good idea. Thank you.']}]\n"
     ]
    }
   ],
   "source": [
    "new_dicts= [] \n",
    "\n",
    "for old_dict in dicts:\n",
    "  foodict = {k: v for k, v in old_dict.items() if (k == 'turns')} \n",
    "  new_dicts.append(foodict)\n",
    "\n",
    "print(len(new_dicts))\n",
    "\n",
    "\n",
    "dicts= []\n",
    "dicts= new_dicts\n",
    "\n",
    "print(dicts[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I1snPgwVHlgt"
   },
   "outputs": [],
   "source": [
    "questions = []\n",
    "answers = []\n",
    "\n",
    "\n",
    "greeting = [\"Hey\", \"Hi\", \"Hello\", \"How are you today?\"]\n",
    "\n",
    "bye = [\"Ok\", \"Okie\", \"Bye\"]\n",
    "\n",
    "for dictionary in dicts:\n",
    "  matrix_QA = dictionary['turns']\n",
    "  \n",
    "  questions.append(random.choice(greeting))\n",
    "    \n",
    "  bot_flag = True \n",
    "  for sentence in matrix_QA:\n",
    "\n",
    "    if bot_flag == True:\n",
    "      answers.append(sentence) \n",
    "      bot_flag = False \n",
    "      continue\n",
    "    else:\n",
    "      questions.append(sentence) \n",
    "      bot_flag = True \n",
    "      continue\n",
    "  if bot_flag == True: \n",
    "    answers.append(random.choice(bye))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rR7KetcnH-2u",
    "outputId": "cb08d0c9-4a61-4bc4-85ca-85ff6ba98f53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4132\n"
     ]
    }
   ],
   "source": [
    "assert len(questions) == len(answers), \"ERROR: The length of the questions and answer matrices are different.\"\n",
    "\n",
    "print(len(questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-G7V9JC0IEz-"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "filepath_to_save = '/content/drive/My Drive/Colab Notebooks/Data/output.tsv' \n",
    "with open(filepath_to_save, 'wt') as out_file:\n",
    "    \n",
    "    tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
    "\n",
    "    \n",
    "    for i in range(len(questions)):\n",
    "        tsv_writer.writerow([questions[i], answers[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CyfQkJsDIWYC"
   },
   "outputs": [],
   "source": [
    "SOS = 0 \n",
    "EOS = 1 \n",
    "\n",
    "class QA_Lang:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.word2index = {}\n",
    "        self.index2word = {0: 'SOS', 1: 'EOS'} # Reserved for start and end token\n",
    "        self.n_words = 2 # Initialize with start and end token\n",
    "\n",
    "    def add_sentence(self, sentence):\n",
    "        for word in sentence.split(' '): \n",
    "            if word not in self.word2index: \n",
    "                self.word2index[word] = self.n_words\n",
    "                self.index2word[self.n_words] = word\n",
    "                self.n_words += 1\n",
    "      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mu8rxVcFIj-n"
   },
   "outputs": [],
   "source": [
    "def text_preprocess(sentence):\n",
    "  sentence = sentence.lower().strip()\n",
    "  normalized_sentence = [c for c in unicodedata.normalize('NFD', sentence) if\n",
    "                        unicodedata.category(c) != 'Mn']\n",
    "\n",
    "  sentence = ''\n",
    "  sentence = ''.join(normalized_sentence)\n",
    "  \n",
    "  sentence = re.sub(r\"([.!?])\", r\" \\1\", sentence)\n",
    "  sentence = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", sentence)\n",
    "\n",
    "  return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "weHzly8ZI-xA"
   },
   "outputs": [],
   "source": [
    "def readQA():\n",
    " \n",
    "\n",
    "    print('Reading lines from file...')\n",
    "\n",
    "    data_path = os.getcwd() + \"/Data/output.tsv\" \n",
    "    lines = open(data_path, encoding='utf-8').read().strip().split('\\n')\n",
    "\n",
    "    TAB_CHARACTER = '\\t'\n",
    "\n",
    "    pairs = [[text_preprocess(sentence) \\\n",
    "              for sentence in line.split(TAB_CHARACTER)] \\\n",
    "              for line in lines]\n",
    "    \n",
    "\n",
    "    \n",
    "    questions = QA_Lang()\n",
    "    answers = QA_Lang()\n",
    "\n",
    "    return questions, answers, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UE0Gu_r1JSlm"
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 50 \n",
    "def filter_data(pairs):\n",
    "\n",
    "    new_pairs = []\n",
    "\n",
    "    for pair in pairs:\n",
    "        question_length = len(pair[0].split(' '))\n",
    "        answer_length = len(pair[1].split(' '))\n",
    "\n",
    "        if question_length < MAX_LENGTH and answer_length < MAX_LENGTH:\n",
    "            new_pairs.append(pair)\n",
    "\n",
    "    return new_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qaepvL8wJh-J"
   },
   "outputs": [],
   "source": [
    "def prepare_data():\n",
    "\n",
    "    questions, answers, pairs = readQA()\n",
    "    print(\"Read \" + str(len(pairs)) + \" sentence pairs\")\n",
    "\n",
    "    pairs = filter_data(pairs)\n",
    "    print(\"filtered down to \" + str(len(pairs)) + \" sentence pairs\")\n",
    "\n",
    "    for pair in pairs:\n",
    "        questions.add_sentence(pair[0])\n",
    "        answers.add_sentence(pair[1])\n",
    "\n",
    "    print(\"The questions object is defined by \" +\n",
    "                        str(questions.n_words) + \" words\")\n",
    "    \n",
    "    print(\"The answers object is defined by \" +\n",
    "                        str(answers.n_words) + \" words\")\n",
    "\n",
    "    return questions, answers, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "MqYqM2--JsWk",
    "outputId": "302cd615-c1fa-4309-88d7-b132b13fb28b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines from file...\n",
      "Read 4132 sentence pairs\n",
      "filtered down to 4130 sentence pairs\n",
      "The questions object is defined by 1829 words\n",
      "The answers object is defined by 2344 words\n"
     ]
    }
   ],
   "source": [
    "questions, answers, pairs = prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pGddyiodK3MK"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size): \n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    " \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "\n",
    "        # Pass the hidden state and the encoder output to the next word input\n",
    "        output, hidden = self.gru(output, hidden) \n",
    "\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        \n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        \n",
    "        self.attention = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attention_combine = nn.Linear(self.hidden_size * 2,\n",
    "                                           self.hidden_size)\n",
    "        \n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        # Forward passes as from the repo\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attention_weights = F.softmax(self.attention(torch.cat((embedded[0],\n",
    "                                                                hidden[0]), 1)),\n",
    "                                                                 dim=1)\n",
    "        \n",
    "        attention_applied = torch.bmm(attention_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attention_applied[0]), 1)\n",
    "        output = self.attention_combine(output).unsqueeze(0)\n",
    "\n",
    "        \n",
    "        output = F.relu(output)\n",
    "\n",
    "        \n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        \n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "\n",
    "        return output, hidden, attention_weights\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iKMUo4nKLpqQ"
   },
   "outputs": [],
   "source": [
    "def tensor_from_sentence(lang, sentence):\n",
    "\n",
    "    indices = [lang.word2index[word] for word in sentence.split(' ')]\n",
    "    indices.append(EOS) \n",
    "\n",
    "    sentence_tensor = torch.tensor(indices, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "    return sentence_tensor\n",
    "\n",
    "def tensors_from_pair(pair):    \n",
    "    input_tensor = tensor_from_sentence(questions, pair[0])\n",
    "    target_tensor = tensor_from_sentence(answers, pair[1])\n",
    "\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ERdix3hJLvKU"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def as_minutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def time_since(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "\n",
    "    return '%s (- %s)' % (as_minutes(s), as_minutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rYdVB4UU6qCm"
   },
   "outputs": [],
   "source": [
    "def BLEU(encoder, attention_decoder, n_examples):\n",
    "    total_score = 0\n",
    "    evaluate_pairs = [random.choice(pairs) for i in range(n_examples)]\n",
    "    for pair in evaluate_pairs:\n",
    "        input_sentence = pair[0]\n",
    "        target_words = [pair[1]]\n",
    "        output_words, _ = evaluate(encoder, attention_decoder, input_sentence)\n",
    "        output_words = output_words\n",
    "        score = sentence_bleu(target_words, output_words)\n",
    "        total_score += score\n",
    "    average_BLEU = total_score/len(pairs)\n",
    "    return average_BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bzXiHodTL6iC"
   },
   "outputs": [],
   "source": [
    "def train(encoder, decoder, iterations, print_at_every=1000, learning_rate=0.01):\n",
    "    \n",
    "\n",
    "    start = time.time() \n",
    "    print_total_loss = 0 \n",
    "    \n",
    "    \n",
    "    #encoder_optimizer = optim.Adam(encoder.parameters(), amsgrad = True, lr=learning_rate)\n",
    "    #decoder_optimizer = optim.Adam(encoder.parameters(), amsgrad = True, lr=learning_rate)\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "    \n",
    "    training_pairs = [tensors_from_pair(random.choice(pairs)) for i in range(iterations)]\n",
    "\n",
    "    \n",
    "    criterion = nn.NLLLoss() \n",
    "    \n",
    "    \n",
    "    for i in range(1, iterations + 1):\n",
    "        training_pair = training_pairs[i - 1]\n",
    "\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder, decoder,\n",
    "                encoder_optimizer, decoder_optimizer, criterion)\n",
    "\n",
    "        print_total_loss += loss\n",
    "\n",
    "        \n",
    "        if i % print_at_every == 0:\n",
    "            print_avg_loss = print_total_loss / print_at_every\n",
    "            print_total_loss = 0 \n",
    "            print('%s (%d %d%%) %.4f' % (time_since(start, i / iterations),\n",
    "                             i, i / iterations * 100, print_avg_loss))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JzgqK08DMBxn"
   },
   "outputs": [],
   "source": [
    "hidden_size = 512 \n",
    "\n",
    "encoder = Encoder(questions.n_words, hidden_size).to(device)\n",
    "attention_decoder = Decoder(hidden_size, answers.n_words, dropout_p=0.2).to(device)\n",
    "\n",
    "iterations = 150000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "EwEid3gQMGOK",
    "outputId": "2934d37b-c708-4719-9fb5-e5b567f4c7d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4m 52s (- 68m 14s) (10000 6%) 2.6334\n",
      "9m 27s (- 61m 29s) (20000 13%) 1.6638\n",
      "14m 2s (- 56m 11s) (30000 20%) 1.0493\n",
      "18m 45s (- 51m 35s) (40000 26%) 0.6735\n",
      "23m 26s (- 46m 53s) (50000 33%) 0.4542\n",
      "28m 5s (- 42m 8s) (60000 40%) 0.3106\n",
      "32m 46s (- 37m 27s) (70000 46%) 0.2306\n",
      "37m 27s (- 32m 46s) (80000 53%) 0.1843\n",
      "42m 9s (- 28m 6s) (90000 60%) 0.1522\n",
      "46m 50s (- 23m 25s) (100000 66%) 0.1327\n",
      "51m 26s (- 18m 42s) (110000 73%) 0.1210\n",
      "56m 7s (- 14m 1s) (120000 80%) 0.1170\n",
      "60m 48s (- 9m 21s) (130000 86%) 0.1182\n",
      "65m 29s (- 4m 40s) (140000 93%) 0.1067\n",
      "70m 9s (- 0m 0s) (150000 100%) 0.1052\n"
     ]
    }
   ],
   "source": [
    "train(encoder, attention_decoder, iterations, print_at_every=(iterations//15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x5OPMF4NXwcw"
   },
   "outputs": [],
   "source": [
    "def inference(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    \n",
    "  with torch.no_grad(): \n",
    "\n",
    "      sentence = text_preprocess(sentence) \n",
    "\n",
    "      input_tensor = tensor_from_sentence(questions, sentence) \n",
    "      input_length = input_tensor.size()[0]\n",
    "\n",
    "      \n",
    "      encoder_hidden = encoder.init_hidden()\n",
    "\n",
    "      \n",
    "      encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "      \n",
    "      for encoder_input in range(input_length):\n",
    "          encoder_output, encoder_hidden = encoder(input_tensor[encoder_input],\n",
    "                                                    encoder_hidden)\n",
    "          encoder_outputs[encoder_input] += encoder_output[0, 0]\n",
    "\n",
    "      \n",
    "      decoder_input = torch.tensor([[SOS]], device=device)\n",
    "\n",
    "      \n",
    "      decoder_hidden = encoder_hidden\n",
    "\n",
    "      \n",
    "      decoded_words = []\n",
    "\n",
    "      \n",
    "      for d_i in range(max_length):\n",
    "          decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                  decoder_input, decoder_hidden, encoder_outputs)\n",
    "          \n",
    "          _, top_i = decoder_output.data.topk(1) \n",
    "\n",
    "          if top_i.item() == EOS: \n",
    "              break \n",
    "          else:\n",
    "              decoded_words.append(answers.index2word[top_i.item()])\n",
    "\n",
    "          decoder_input = top_i.squeeze().detach()\n",
    "\n",
    "      return ' '.join(decoded_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zIBmeKBx6t-e"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L7R4MMSiLnqi"
   },
   "outputs": [],
   "source": [
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
    "                       ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AmtBQtgELy18"
   },
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensor_from_sentence(questions, sentence)\n",
    "        if input_tensor.size()[0] > 50:\n",
    "            input_tensor = input_tensor[:50]\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.init_hidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS]], device=device)  \n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(answers.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words[:-1], decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "EJ3d76hiequQ",
    "outputId": "30490cc2-8e24-4ea1-e6b3-a7d39dd58f9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter bye to quit\n",
      "User: Hello\n",
      "Bot: hello how may i help you ?\n",
      "User: I need help with a gift\n",
      "Bot: i have some ideas .\n",
      "User: lets hear them\n",
      "Bot: what about a facial wax ?\n",
      "User: yeah that's a great idea\n",
      "Bot: would you like to buy .\n",
      "User: yes thank you\n",
      "Bot: you re welcome !\n",
      "User: bye\n",
      "Okay bye..\n"
     ]
    }
   ],
   "source": [
    "# Run this code block to test chatbot\n",
    "print(\"Enter bye to quit\")\n",
    "while (1):\n",
    "  \n",
    "  user_input = input(\"User: \")\n",
    "\n",
    "  user_input = str(user_input)\n",
    "\n",
    "  if user_input == 'bye':\n",
    "    print(\"Bot: Okay bye..\")\n",
    "    break;\n",
    "  else:\n",
    "    print(\"Bot: \" + str(inference(encoder, attention_decoder, user_input)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "colab_type": "code",
    "id": "qizW7dvhfo4X",
    "outputId": "7fd7c833-926e-4ea1-cd8e-1031e680d4f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type EncoderRNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type GRU. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type AttnDecoderRNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "encoder_name = 'encoder_serialized.pt'\n",
    "decoder_name = 'decoder_serialized.pt'\n",
    "print('Saving model...')\n",
    "torch.save(encoder, encoder_name)\n",
    "torch.save(attention_decoder, decoder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3cgzit8m8tEL"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "BLEUScore = BLEU(encoder, attention_decoder, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "um2Jiv6C8uuq",
    "outputId": "56953dad-8467-4eff-9e8a-4586eb27a5a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw BLEU score of the whole model: 8.3263%\n",
      "BLEU score of the whole mdoel: 83.2634%\n"
     ]
    }
   ],
   "source": [
    "print('Raw BLEU score of the whole model: {:.4%}'.format(BLEUScore))\n",
    "print('BLEU score of the whole mdoel: {:.4%}'.format(BLEUScore * 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2-Dmz3oUB3k1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "chatbot4.0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
